{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T4hmZWAgoFFi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # type: ignore\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.16.1'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Q2MuScAonrF"
      },
      "outputs": [],
      "source": [
        "# Path to the parent directory containing \"folder 1\"\n",
        "parent_dir = pathlib.Path(\"C:\\\\Users\\\\Rohan Sharma\\\\Desktop\\\\Electronic-Components-Classification-main\")\n",
        "\n",
        "# Path to \"Dataset\" inside \"Electronic-Components-Classification-main\"\n",
        "base_dir = parent_dir / \"Dataset\"\n",
        "VALIDATION_SPLIT = 0.3\n",
        "SEED = 100\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxAQF1ehozEF",
        "outputId": "08591f15-db23-46e6-9114-9ad62c3b6309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2829 images belonging to 6 classes.\n",
            "Found 1209 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wmSQfWupBx-",
        "outputId": "b080901b-89de-4bb6-ef3f-02a5d6eeb350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((32, 224, 224, 3), (32, 6))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "    break\n",
        "image_batch.shape, label_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7fLiCvvpKw0",
        "outputId": "96c058b6-5ac4-45d6-d4e5-bdb5e7da5a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Capacitor': 0, 'Diode': 1, 'IC': 2, 'Inductor': 3, 'Resistor': 4, 'Transformer': 5}\n"
          ]
        }
      ],
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0usyfegpX6V",
        "outputId": "5a911c83-fa82-4123-97fa-00e81ab413da"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rqY3jeGpcqW"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyx0K7OvplKN"
      },
      "outputs": [],
      "source": [
        "# data_augmentation = tf.keras.Sequential([\n",
        "#     tf.keras.layers.RandomFlip('horizontal'),\n",
        "#     tf.keras.layers.RandomRotation(0.2)\n",
        "# ])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=IMG_SHAPE),\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW1NOsyGp3qU"
      },
      "outputs": [],
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRooWBTBqAcN",
        "outputId": "02117008-d727-4c4b-ec51-ab122fe0caf5"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D5g4pAEqHhf",
        "outputId": "87a8d46d-4ce6-4e76-d2ff-f53c56e33029"
      },
      "outputs": [],
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xy1uIvoUoM7",
        "outputId": "b1299efd-7657-4282-c35d-f93e4aa23cd7"
      },
      "outputs": [],
      "source": [
        "loss0, accuracy0 = model.evaluate(val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3_fMWOIqJ61",
        "outputId": "89e276ce-f051-4782-e203-dfb67e749f1a"
      },
      "outputs": [],
      "source": [
        "# Convert DirectoryIterator to a tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3), (None, 6))\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3), (None, 6))\n",
        ")\n",
        "\n",
        "# Repeat the train_dataset for the specified number of epochs\n",
        "initial_epochs = 10\n",
        "train_dataset = train_dataset.repeat(initial_epochs)\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch=len(train_generator), \n",
        "                    epochs=initial_epochs, \n",
        "                    validation_data=val_dataset, \n",
        "                    validation_steps=len(val_generator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-ZiaRGLdzkDg",
        "outputId": "d7dbdde9-b1ae-492a-e253-564926a67206"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,2.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,  # Rotate images by random degrees (±20 degrees)\n",
        "    width_shift_range=0.2,  # Shift images horizontally (±20% of total width)\n",
        "    height_shift_range=0.2,  # Shift images vertically (±20% of total height)\n",
        "    horizontal_flip=True,  # Flip images horizontally\n",
        "    vertical_flip=True,  # Flip images vertically\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    validation_split=VALIDATION_SPLIT  # Split data into training and validation sets\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False,\n",
        "    seed=SEED,\n",
        "    subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DirectoryIterator to a tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3), (None, 6))\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3), (None, 6))\n",
        ")\n",
        "\n",
        "# Repeat the train_dataset for the specified number of epochs\n",
        "initial_epochs = 10\n",
        "train_dataset = train_dataset.repeat(initial_epochs)\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch=len(train_generator), \n",
        "                    epochs=initial_epochs, \n",
        "                    validation_data=val_dataset, \n",
        "                    validation_steps=len(val_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,2.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isxfZPKqzrAs"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA6U-0aOzrkd",
        "outputId": "43b54a70-e65a-4d53-ee6b-e78a487ea705"
      },
      "outputs": [],
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI7W0yK1zvwb"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApkEPUP3z3ij",
        "outputId": "b13c7607-970b-44fd-9860-dc97c954e388"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_LpNiV5z4Eh",
        "outputId": "7ab6397d-3bfa-45fc-87b4-1b7e53290df0"
      },
      "outputs": [],
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3G65M5lz8hO",
        "outputId": "b4135547-0db2-48f6-87de-343c8c7524c9"
      },
      "outputs": [],
      "source": [
        "# Convert DirectoryIterator to a tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3) , (None, 6) )\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, 224, 224, 3), (None, 6) )\n",
        ")\n",
        "\n",
        "# Repeat the train_dataset for the total number of epochs\n",
        "initial_epochs = 10\n",
        "fine_tune_epochs = 8\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "train_dataset = train_dataset.repeat(total_epochs)\n",
        "\n",
        "# Calculate initial epoch for fine-tuning\n",
        "initial_epoch_fine = initial_epochs if history is None else history.epoch[-1] + 1\n",
        "\n",
        "history_fine = model.fit(train_dataset, \n",
        "                         steps_per_epoch=len(train_generator), \n",
        "                         epochs=total_epochs, \n",
        "                         initial_epoch=initial_epoch_fine,\n",
        "                         validation_data=val_dataset, \n",
        "                         validation_steps=len(val_generator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ZZIBt-ZH6AtZ",
        "outputId": "c9508afe-8326-4bd6-91bd-277655e77116"
      },
      "outputs": [],
      "source": [
        "acc = history_fine.history['accuracy']\n",
        "val_acc = history_fine.history['val_accuracy']\n",
        "\n",
        "loss = history_fine.history['loss']\n",
        "val_loss = history_fine.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),0.9])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.5])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Electronic_Components_TFLite.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
